{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "import json\n",
    "import os\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import folium as fl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_weather = pd.read_csv('../data/raw/weather/weather.csv', sep = \"\\t\")\n",
    "data_corona_de = pd.read_csv(\"../data/raw/corona/de_corona.csv\", sep = \"\\t\")\n",
    "with open(\"../data/raw/metadata/de_metadata.json\") as f:\n",
    "    data_meta_de = json.load(f)\n",
    "with open(\"../data/raw/shapefiles/de.geojson\") as f:\n",
    "    data_geo = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_weather.shape)\n",
    "data_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(data_weather.columns))\n",
    "np.unique(data_weather[\"iso3166-2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in data_weather:\n",
    "    #print(sum(pd.isnull(data_weather[i])))\n",
    "    if sum(pd.isnull(data_weather[i])) != 0:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering for germany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_codes = ['DE-BB', 'DE-BE', 'DE-BW', 'DE-BY', 'DE-HB', 'DE-HE', 'DE-HH', 'DE-MV', 'DE-NI', 'DE-NW', \n",
    "            'DE-RP', 'DE-SH', 'DE-SL', 'DE-SN', 'DE-ST', 'DE-TH']\n",
    "mask = np.isin(data_weather, de_codes) \n",
    "data_weather_de = data_weather[mask]\n",
    "\n",
    "print(data_weather_de.shape)\n",
    "np.unique(data_weather_de[\"iso3166-2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the filtered dataset for germany\n",
    "def saving_csv(file, name):\n",
    "    file.to_csv(f'../data/interim/weather_{name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_csv(data_weather_de, \"germany\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_corona_de.shape)\n",
    "data_corona_de.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# min, mean, median, and max of regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masking for different regions\n",
    "region_names = ['DE_BB', 'DE_BE', 'DE_BW', 'DE_BY', 'DE_HB', 'DE_HE', 'DE_HH', 'DE_MV', 'DE_NI', 'DE_NW', \n",
    "            'DE_RP', 'DE_SH', 'DE_SL', 'DE_SN', 'DE_ST', 'DE_TH']\n",
    "for codes, names in zip(de_codes, de_codes):\n",
    "    mask = np.isin(data_weather_de, codes)\n",
    "    region_data = data_weather_de[mask]\n",
    "    saving_csv(region_data, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for numerical columns, they are from index 2 and onwards\n",
    "weather_columns = list(data_weather.columns)\n",
    "print(weather_columns)\n",
    "weather_numerical_columns = weather_columns[2:9]\n",
    "weather_numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sum_numeric = {}\n",
    "for region in de_codes:\n",
    "    data = pd.read_csv(f'../data/interim/weather_{region}.csv')\n",
    "    dict_sum_numeric.update({region:{}})\n",
    "    for col in range(2,len(list(data_weather.columns))):\n",
    "        dict_sum_numeric[region].update({list(data_weather.columns)[col]:[min(data[list(data_weather.columns)[col]]), \n",
    "                                                             data[list(data_weather.columns)[col]].mean(), \n",
    "                                                             data[list(data_weather.columns)[col]].median(), \n",
    "                                                            max(data[list(data_weather.columns)[col]])]})\n",
    "print(dict_sum_numeric[\"DE-BB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.FigureWidget(data=go.Bar(y=dict_sum_numeric[\"DE-BB\"][\"WindSpeed\"], x = [\"min\", \"mean\", \"median\", \"max\"]))\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary to convert the region code into the region name\n",
    "dic_convert = {data_meta_de[\"country_metadata\"][i][\"iso3166-2_name_en\"].replace(\"Ã¼\", \"ü\"):\n",
    "               data_meta_de[\"country_metadata\"][i][\"iso3166-2_code\"]\n",
    "              for i in range(len(data_meta_de[\"country_metadata\"]))\n",
    "              }\n",
    "#insert a column into corona dataframe with the region name as well\n",
    "data_corona_de[\"region\"] = data_corona_de[\"region_code\"].map(dic_convert)\n",
    "\n",
    "#create a new dataframe having region code and the confirmed cases\n",
    "data_corona_region = data_corona_de.groupby(by = \"region\")[\"confirmed_addition\"].sum().reset_index()\n",
    "\n",
    "#create a dictionary having the total population for each region\n",
    "population_map = {data_meta_de[\"country_metadata\"][i][\"iso3166-2_code\"]:\n",
    "                  data_meta_de[\"country_metadata\"][i][\"population\"] \n",
    "                  for i in range(len(data_meta_de[\"country_metadata\"]))\n",
    "                 }\n",
    "#insert a column population into data coron by region\n",
    "data_corona_region[\"population\"] = data_corona_region[\"region\"].map(population_map)\n",
    "\n",
    "#insert a coulm that cases/population\n",
    "data_corona_region[\"relation\"] = data_corona_region[\"confirmed_addition\"]/data_corona_region[\"population\"]*100\n",
    "\n",
    "data_corona_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the folium.Choropleth\n",
    "m = fl.Map(\n",
    "location = [51.3, 10.3],\n",
    "    zoom_start = 6,)\n",
    "\n",
    "fl.Choropleth(\n",
    "    geo_data = data_geo,\n",
    "    name = \"cases\",\n",
    "    data = data_corona_region,\n",
    "    columns = [\"region\", \"relation\"],\n",
    "    key_on = \"properties.iso_3166_2\",\n",
    "    fill_color = \"OrRd\",\n",
    "    fill_opacity = .6,\n",
    "    line_opacity = .5,\n",
    "    legend_name = \"Number of Cases\",\n",
    ").add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}