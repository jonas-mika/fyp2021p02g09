{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "import json\n",
    "import os\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import folium as fl\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_weather_1 = pd.read_csv('../data/raw/weather/weather.csv', sep = \"\\t\")\n",
    "data_weather_2 = pd.read_csv('../data/raw/weather/weather2.csv', sep = \"\\t\")\n",
    "data_corona_de = pd.read_csv(\"../data/raw/corona/de_corona.csv\", sep = \"\\t\")\n",
    "with open(\"../data/raw/metadata/de_metadata.json\") as f:\n",
    "    data_meta_de = json.load(f)\n",
    "with open(\"../data/raw/shapefiles/de.geojson\") as f:\n",
    "    data_geo = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_weather_1.shape)\n",
    "data_weather_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(data_weather_1.columns))\n",
    "np.unique(data_weather_1[\"iso3166-2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [data_weather_1, data_weather_2]\n",
    "data_weather = pd.concat(frames)\n",
    "data_weather.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in data_weather:\n",
    "    #print(sum(pd.isnull(data_weather[i])))\n",
    "    if sum(pd.isnull(data_weather[i])) != 0:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering for germany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_codes = ['DE-BB', 'DE-BE', 'DE-BW', 'DE-BY', 'DE-HB', 'DE-HE', 'DE-HH', 'DE-MV', 'DE-NI', 'DE-NW', \n",
    "            'DE-RP', 'DE-SH', 'DE-SL', 'DE-SN', 'DE-ST', 'DE-TH']\n",
    "mask = np.isin(data_weather, de_codes) \n",
    "data_weather_de = data_weather[mask]\n",
    "\n",
    "print(data_weather_de.shape)\n",
    "np.unique(data_weather_de[\"iso3166-2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the filtered dataset for germany\n",
    "def saving_csv(file, name):\n",
    "    file.to_csv(f'../data/interim/weather_{name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_csv(data_weather_de, \"germany\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_corona_de.shape)\n",
    "data_corona_de.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# min, mean, median, and max of regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masking for different regions\n",
    "region_names = ['DE_BB', 'DE_BE', 'DE_BW', 'DE_BY', 'DE_HB', 'DE_HE', 'DE_HH', 'DE_MV', 'DE_NI', 'DE_NW', \n",
    "            'DE_RP', 'DE_SH', 'DE_SL', 'DE_SN', 'DE_ST', 'DE_TH']\n",
    "for codes, names in zip(de_codes, de_codes):\n",
    "    mask = np.isin(data_weather_de, codes)\n",
    "    region_data = data_weather_de[mask]\n",
    "    saving_csv(region_data, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for numerical columns, they are from index 2 and onwards\n",
    "weather_columns = list(data_weather.columns)\n",
    "print(weather_columns)\n",
    "weather_numerical_columns = weather_columns[2:9]\n",
    "weather_numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sum_numeric = {}\n",
    "for region in de_codes:\n",
    "    data = pd.read_csv(f'../data/interim/weather_{region}.csv')\n",
    "    dict_sum_numeric.update({region:{}})\n",
    "    for col in range(2,len(list(data_weather.columns))):\n",
    "        dict_sum_numeric[region].update({list(data_weather.columns)[col]:[min(data[list(data_weather.columns)[col]]), \n",
    "                                                             data[list(data_weather.columns)[col]].mean(), \n",
    "                                                             data[list(data_weather.columns)[col]].median(), \n",
    "                                                            max(data[list(data_weather.columns)[col]])]})\n",
    "print(dict_sum_numeric[\"DE-BB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.FigureWidget(data=go.Bar(y=dict_sum_numeric[\"DE-BB\"][\"WindSpeed\"], x = [\"min\", \"mean\", \"median\", \"max\"]))\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary to convert the region code into the region name\n",
    "dic_convert = {data_meta_de[\"country_metadata\"][i][\"iso3166-2_name_en\"].replace(\"Ã¼\", \"ü\"):\n",
    "               data_meta_de[\"country_metadata\"][i][\"iso3166-2_code\"]\n",
    "              for i in range(len(data_meta_de[\"country_metadata\"]))\n",
    "              }\n",
    "#insert a column into corona dataframe with the region name as well\n",
    "data_corona_de[\"region\"] = data_corona_de[\"region_code\"].map(dic_convert)\n",
    "\n",
    "#create a new dataframe having region code and the confirmed cases\n",
    "data_corona_region = data_corona_de.groupby(by = \"region\")[\"confirmed_addition\"].sum().reset_index()\n",
    "\n",
    "#create a dictionary having the total population for each region\n",
    "population_map = {data_meta_de[\"country_metadata\"][i][\"iso3166-2_code\"]:\n",
    "                  data_meta_de[\"country_metadata\"][i][\"population\"] \n",
    "                  for i in range(len(data_meta_de[\"country_metadata\"]))\n",
    "                 }\n",
    "#insert a column population into data coron by region\n",
    "data_corona_region[\"population\"] = data_corona_region[\"region\"].map(population_map)\n",
    "\n",
    "#insert a coulm that cases/population\n",
    "data_corona_region[\"relation\"] = data_corona_region[\"confirmed_addition\"]/data_corona_region[\"population\"]*100\n",
    "\n",
    "data_corona_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the folium.Choropleth\n",
    "m = fl.Map(\n",
    "location = [51.3, 10.3],\n",
    "    zoom_start = 6,)\n",
    "\n",
    "fl.Choropleth(\n",
    "    geo_data = data_geo,\n",
    "    name = \"cases\",\n",
    "    data = data_corona_region,\n",
    "    columns = [\"region\", \"relation\"],\n",
    "    key_on = \"properties.iso_3166_2\",\n",
    "    fill_color = \"OrRd\",\n",
    "    fill_opacity = .6,\n",
    "    line_opacity = .5,\n",
    "    legend_name = \"Number of Cases\",\n",
    ").add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_corona_de.merge(data_weather, left_on = [\"date\", \"region\"], right_on =  [\"date\", \"iso3166-2\"])\n",
    "df = df.drop([\"iso3166-2\"], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson correlation with log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = ['RelativeHumiditySurface', 'SolarRadiation','Surfacepressure', 'TemperatureAboveGround', 'Totalprecipitation',\n",
    "       'UVIndex', 'WindSpeed']\n",
    "significance_threshold = 0.001 / (len(Xs)*3)\n",
    "corrs = []\n",
    "pvalues = []\n",
    "for var in Xs:\n",
    "    corr, pvalue = pearsonr(np.log(df[\"confirmed_addition\"]), df[var])\n",
    "    print(f\"{var}\\n{corr:.3f}\\t{pvalue}\\t{pvalue < significance_threshold}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spearman correlation with log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in Xs:\n",
    "    corr, pvalue = spearmanr(np.log(df[\"confirmed_addition\"]), df[var])\n",
    "    print(f\"{var}\\n{corr:.3f}\\t{pvalue}\\t{pvalue < significance_threshold}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thought it could be interesting to see if summing up x days could result in another correlation\n",
    "and since it can take up to 14 days before symptoms of covid-19 can be seen, it would make sense to\n",
    "see what happened during those 14 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_sum(num_days):\n",
    "    run = ['RelativeHumiditySurface', 'SolarRadiation','Surfacepressure', 'TemperatureAboveGround', 'Totalprecipitation',\n",
    "           'UVIndex', 'WindSpeed']\n",
    "    df_rolling_x = data_corona_de.merge(data_weather, left_on = [\"date\", \"region\"], right_on =  [\"date\", \"iso3166-2\"])\n",
    "    df_rolling_x = df_rolling_x.drop([\"iso3166-2\"], axis = 1)\n",
    "    for variation in run:\n",
    "        new = []\n",
    "        for i in range(len(list(df_rolling_x[variation]))):\n",
    "            if i == 0:\n",
    "                new.append(list(df_rolling_x[variation])[i])\n",
    "                continue\n",
    "            if i < num_days and i > 0 :\n",
    "                new.append(sum(list(df_rolling_x[variation])[0:i+1]))\n",
    "                continue\n",
    "            new.append(sum(list(df_rolling_x[variation])[i-num_days:i]))\n",
    "        df_rolling_x[variation] = new\n",
    "    return df_rolling_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolling_7 = rolling_sum(7)\n",
    "df_rolling_14 =  rolling_sum(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates summary for three spearman correlations with log on the cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in Xs:\n",
    "    corr, pvalue = spearmanr(np.log(df[\"confirmed_addition\"]), df[var])\n",
    "    corr7, pvalue7 = spearmanr(np.log(df_rolling_7[\"confirmed_addition\"]), df_rolling_7[var])\n",
    "    corr14, pvalue14 = spearmanr(np.log(df_rolling_14[\"confirmed_addition\"]), df_rolling_14[var])\n",
    "    print(f\"{var}:\\nCorrelation coefficient: (standard: {corr:.3f}, 7 days: {corr7:.3f}, 14 days: {corr14:.3f})\\nPvalue: (standard: {pvalue}, 7 days: {pvalue7}, 14 days: {pvalue14})\\nHolds the significance threshold: (standard: {pvalue < significance_threshold}, 7 days: {pvalue7 < significance_threshold}, 14 days: {pvalue14 < significance_threshold})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivariable correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " Xs.append(\"const\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariable_correlation(data):\n",
    "    data = sm.add_constant(data)\n",
    "    est = sm.OLS(np.log(data[\"confirmed_addition\"]), data[Xs], hsconst = True).fit()\n",
    "    return est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multivariable_correlation(df_rolling_7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
